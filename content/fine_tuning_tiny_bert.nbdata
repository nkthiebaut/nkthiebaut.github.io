Title: Speed and power: fine-tuning distilled transformers models
Slug: fine_tuning_tiny_bert
Date: 2021-02-19 15:00
Category: posts
Tags: python, machine learning, transformers
Author: Nicolas Thiebaut
Summary: Leaner and faster Transformers with distillation. Fine-tuning BERT-tiny in a couple of minutes with PyTorch.
featured_image: https://github.com/nkthiebaut/nkthiebaut.github.io/blob/master/images/knowledge_distillation.png?raw=true
